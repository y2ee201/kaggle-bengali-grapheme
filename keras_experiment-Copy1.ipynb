{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import time\n",
    "import fastparquet\n",
    "from scipy.ndimage import median_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200840 entries, 0 to 200839\n",
      "Data columns (total 5 columns):\n",
      "image_id               200840 non-null object\n",
      "grapheme_root          200840 non-null int64\n",
      "vowel_diacritic        200840 non-null int64\n",
      "consonant_diacritic    200840 non-null int64\n",
      "grapheme               200840 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "training_labels = pd.read_csv('./train.csv')\n",
    "training_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\y2ee2\\anaconda3\\envs\\devenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200840, 168)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_grapheme_root = OneHotEncoder()\n",
    "enc_grapheme_root.fit(training_labels.grapheme_root.values.reshape(-1,1))\n",
    "labels_grapheme = enc_grapheme_root.transform(training_labels.grapheme_root.values.reshape(-1,1))\n",
    "labels_grapheme = pd.DataFrame(labels_grapheme.toarray(), \n",
    "                               columns=['grapheme_' + str(i) \n",
    "                                        for i in range(labels_grapheme.shape[1])])\n",
    "labels_grapheme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\y2ee2\\anaconda3\\envs\\devenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200840, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_vowel_diacritic = OneHotEncoder()\n",
    "enc_vowel_diacritic.fit(training_labels.vowel_diacritic.values.reshape(-1,1))\n",
    "labels_vowel = enc_vowel_diacritic.transform(training_labels.vowel_diacritic.values.reshape(-1,1))\n",
    "labels_vowel = pd.DataFrame(labels_vowel.toarray(), \n",
    "                            columns = ['vowel_' + str(i) \n",
    "                                       for i in range(labels_vowel.shape[1])])\n",
    "labels_vowel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\y2ee2\\anaconda3\\envs\\devenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200840, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_consonant_diacritic = OneHotEncoder()\n",
    "enc_consonant_diacritic.fit(training_labels.consonant_diacritic.values.reshape(-1,1))\n",
    "labels_consonent = enc_consonant_diacritic.transform(training_labels.consonant_diacritic.values.reshape(-1,1))\n",
    "labels_consonent = pd.DataFrame(labels_consonent.toarray(), \n",
    "                                columns = ['consonant_'+str(i) \n",
    "                                           for i in range(labels_consonent.shape[1])])\n",
    "labels_consonent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 187)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = training_labels[['image_id']]\n",
    "# df_train['image_id'] = df_train['image_id']+'.jpg'\n",
    "df_train = pd.concat([df_train, labels_grapheme, labels_vowel, labels_consonent], \n",
    "                     axis = 1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Compatible with tensorflow backend\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true[:,0:168], 1), y_pred[:,0:168], \n",
    "                        tf.ones_like(y_pred[:,0:168]))\n",
    "        pt_0 = tf.where(tf.equal(y_true[:,0:168], 0), y_pred[:,0:168], \n",
    "                        tf.zeros_like(y_pred[:,0:168]))\n",
    "        fl = -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "        \n",
    "        pt_1 = tf.where(tf.equal(y_true[:,168:179], 1), y_pred[:,168:179], \n",
    "                        tf.ones_like(y_pred[:,168:179]))\n",
    "        pt_0 = tf.where(tf.equal(y_true[:,168:179], 0), y_pred[:,168:179], \n",
    "                        tf.zeros_like(y_pred[:,168:179]))\n",
    "        fl_1 = -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "        \n",
    "        pt_1 = tf.where(tf.equal(y_true[:,179:186], 1), y_pred[:,179:186], \n",
    "                        tf.ones_like(y_pred[:,179:186]))\n",
    "        pt_0 = tf.where(tf.equal(y_true[:,179:186], 0), y_pred[:,179:186], \n",
    "                        tf.zeros_like(y_pred[:,179:186]))\n",
    "        fl_2 = -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "        \n",
    "        return 2*fl + fl_1 + fl_2\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_0</th>\n",
       "      <th>grapheme_1</th>\n",
       "      <th>grapheme_2</th>\n",
       "      <th>grapheme_3</th>\n",
       "      <th>grapheme_4</th>\n",
       "      <th>grapheme_5</th>\n",
       "      <th>grapheme_6</th>\n",
       "      <th>grapheme_7</th>\n",
       "      <th>grapheme_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vowel_8</th>\n",
       "      <th>vowel_9</th>\n",
       "      <th>vowel_10</th>\n",
       "      <th>consonant_0</th>\n",
       "      <th>consonant_1</th>\n",
       "      <th>consonant_2</th>\n",
       "      <th>consonant_3</th>\n",
       "      <th>consonant_4</th>\n",
       "      <th>consonant_5</th>\n",
       "      <th>consonant_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_0  grapheme_1  grapheme_2  grapheme_3  grapheme_4  \\\n",
       "0  Train_0         0.0         0.0         0.0         0.0         0.0   \n",
       "1  Train_1         0.0         0.0         0.0         0.0         0.0   \n",
       "2  Train_2         0.0         0.0         0.0         0.0         0.0   \n",
       "3  Train_3         0.0         0.0         0.0         0.0         0.0   \n",
       "4  Train_4         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   grapheme_5  grapheme_6  grapheme_7  grapheme_8  ...  vowel_8  vowel_9  \\\n",
       "0         0.0         0.0         0.0         0.0  ...      0.0      1.0   \n",
       "1         0.0         0.0         0.0         0.0  ...      0.0      0.0   \n",
       "2         0.0         0.0         0.0         0.0  ...      0.0      0.0   \n",
       "3         0.0         0.0         0.0         0.0  ...      0.0      0.0   \n",
       "4         0.0         0.0         0.0         0.0  ...      0.0      1.0   \n",
       "\n",
       "   vowel_10  consonant_0  consonant_1  consonant_2  consonant_3  consonant_4  \\\n",
       "0       0.0          0.0          0.0          0.0          0.0          0.0   \n",
       "1       0.0          1.0          0.0          0.0          0.0          0.0   \n",
       "2       0.0          0.0          0.0          0.0          0.0          0.0   \n",
       "3       0.0          0.0          0.0          1.0          0.0          0.0   \n",
       "4       0.0          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   consonant_5  consonant_6  \n",
       "0          1.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          1.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4          1.0          0.0  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "ia.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160672, 187), (40168, 187))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df, lab1, lab2 = train_test_split(df_train, \n",
    "                                                 df_train.image_id, \n",
    "                                                 test_size=0.2, random_state=42)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['image_id'] = df_train['image_id']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200840 images.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255.,\n",
    "                                 zoom_range=0.3, \n",
    "                                 shear_range=15, \n",
    "                                 rotation_range=25, \n",
    "                                 height_shift_range=0.2, \n",
    "                                 width_shift_range=0.2, \n",
    "                                 validation_split=0.2\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        directory='./train_images/',\n",
    "        x_col=\"image_id\",\n",
    "        y_col=df_train.columns[1:],\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode=\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             multiple                  23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 186)               47802     \n",
      "=================================================================\n",
      "Total params: 40,544,570\n",
      "Trainable params: 40,491,450\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "size = 128\n",
    "\n",
    "inputs = Input(shape=(size, size, 3))\n",
    "bn = BatchNormalization()(inputs)\n",
    "pre_trained_model = ResNet50(weights=None, \n",
    "                             include_top=False, \n",
    "                             # input_shape=(size, size, 3), \n",
    "                             # pooling='avg'\n",
    "                            )\n",
    "x = pre_trained_model(inputs)\n",
    "flat = Flatten()(x)\n",
    "# flat = pre_trained_model.outputs\n",
    "dense = Dense(512, activation='relu')(flat)\n",
    "dense = Dropout(0.2)(dense)\n",
    "dense = Dense(256, activation='relu')(dense)\n",
    "dense = Dropout(0.4)(dense)\n",
    "dense = Dense(186, activation='sigmoid')(dense)\n",
    "\n",
    "cnn = Model(inputs = inputs, outputs=dense)\n",
    "\n",
    "cnn.compile(optimizer='adam', \n",
    "            loss=[focal_loss(alpha=.25, gamma=2)], \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 40s 13s/step - loss: inf - acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 1s 273ms/step - loss: inf - acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 1s 275ms/step - loss: inf - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit_generator(train_generator, \n",
    "                                     steps_per_epoch=3, \n",
    "                                     epochs=3,\n",
    "                                     # validation_data=image_generator_test(batch_size = 16),\n",
    "                                     # validation_steps=1\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
